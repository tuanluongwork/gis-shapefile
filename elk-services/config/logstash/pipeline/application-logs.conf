input {
  # Direct file input for all logs in logs/ folder
  file {
    path => ["/usr/share/logstash/app-logs/*", "/usr/share/logstash/app-logs/**/*"]
    start_position => "beginning"
    codec => json_lines
    tags => ["application"]
  }
}

filter {
  # Process JSON structured logs
  if "application" in [tags] {
    # JSON logs are already formatted, timestamp is already parsed
    # Extract correlation ID and context from structured message
    if [message] and "|" in [message] {
      grok {
        match => { "message" => "(?<log_message>.*?) \| correlation_id:(?<correlation_id>[^\s]+)(?<context_data>.*)" }
        tag_on_failure => ["_grok_parse_failure_correlation"]
      }
      
      # Replace message with the clean log message
      if [log_message] {
        mutate {
          replace => { "message" => "%{log_message}" }
        }
      }
      
      # Parse additional context data
      if [context_data] {
        grok {
          match => { "context_data" => " (?<key>\w+):(?<value>[^\s]+)" }
          tag_on_failure => []
        }
      }
    }
    
    # Ensure timestamp is properly formatted for Elasticsearch
    if [timestamp] {
      date {
        match => [ "timestamp", "ISO8601", "yyyy-MM-dd'T'HH:mm:ss.SSSSSSSSS'Z'" ]
        target => "@timestamp"
      }
    }
  }
  
  # Parse application logs from other sources (filebeat, etc)
  else if [fields][log_type] == "application" {
    # Parse structured log messages
    if [message] =~ /^\{.*\}$/ {
      json {
        source => "message"
      }
    }
    
    # Extract log level from message if not already present
    if ![level] {
      grok {
        match => { "message" => "(?<level>DEBUG|INFO|WARN|WARNING|ERROR|FATAL)" }
      }
    }
    
    # Parse timestamp if present
    if [timestamp] {
      date {
        match => [ "timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss.SSS" ]
      }
    }
    
    # Extract thread information
    grok {
      match => { "message" => "\[(?<thread_id>Thread-\d+)\]" }
      tag_on_failure => []
    }
    
    # Extract correlation ID if present
    grok {
      match => { "message" => "correlation_id:\s*(?<correlation_id>[^\s]+)" }
      tag_on_failure => []
    }
  }
  
  # Add common fields
  mutate {
    add_field => { 
      "[@metadata][index_prefix]" => "app-logs"
      "application" => "myapp"
      "log_source" => "application"
    }
  }
  
  # Convert log level to lowercase for consistency
  if [level] {
    mutate {
      lowercase => [ "level" ]
    }
  }
  
  # Add component information from logger name
  if [logger] {
    mutate {
      add_field => { "component" => "%{logger}" }
    }
  }
  
  # Remove temporary fields
  mutate {
    remove_field => [ "log_message", "context_data", "key", "value" ]
  }
  
  # Remove empty fields
  if [message] == "" {
    drop { }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "%{[@metadata][index_prefix]}-%{+YYYY.MM.dd}"
  }
  
  # Debug output (comment out in production)
  stdout {
    codec => rubydebug {
      metadata => true
    }
  }
}